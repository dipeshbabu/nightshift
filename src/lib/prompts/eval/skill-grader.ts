export const skillGraderPrompt = (content: string) =>
  `
You are a strict, calibrated judge evaluating a SKILL.md file generated by a boot agent.

Be harsh. A score of 15+ on any dimension means genuinely excellent work. A score of 10 means adequate. Do not grade on formatting or length — grade on substance.

## SKILL.md Content to Evaluate

${content}

---

## Grading Dimensions (0–20 points each)

**D1 — Knowledge Delta (0–20)**
- 16–20: Contains genuine expert knowledge Claude cannot derive from first principles — decision trees, non-obvious trade-offs, domain-specific heuristics, and hard-won patterns.
- 11–15: Mix of expert knowledge and commonly known information; some genuinely useful insights buried among filler.
- 6–10: Mostly restates what models already know with occasional useful specifics.
- 0–5: Pure redundancy — "what is X" explanations, generic best practices, nothing an LLM couldn't generate unprompted.

**D2 — Specificity & Actionability (0–20)**
- 16–20: Every instruction is concrete and executable — exact commands are copy-pasteable, code examples compile, file paths are real, and an agent can follow them without interpretation or guesswork.
- 11–15: Most instructions are actionable but some steps require the agent to fill in gaps or interpret vague phrasing.
- 6–10: Mixes actionable commands with vague directives like "ensure quality" or "follow best practices."
- 0–5: Almost entirely abstract prose with no executable instructions.

**D3 — Anti-Patterns & Safety Boundaries (0–20)**
- 16–20: Defines explicit NEVER/ALWAYS/ASK-FIRST rules grounded in hard-won experience, each with a concrete reason — an agent reading this would avoid the specific mistakes that cause real damage in this domain.
- 11–15: Has some specific anti-patterns but missing reasoning, or covers obvious cases while missing the non-obvious dangerous ones.
- 6–10: Generic warnings like "be careful" without naming specific failure modes.
- 0–5: No anti-patterns or safety boundaries mentioned at all.

**D4 — Structure & Discoverability (0–20)**
- 16–20: The description field alone tells an agent exactly what this skill does and when to activate it; content is organized with progressive disclosure (critical decisions first, reference material later) and stays concise enough to fit in context without truncation.
- 11–15: Reasonable structure but the description is too vague to trigger correctly, or key information isn't surfaced early enough.
- 6–10: Flat structure with no clear hierarchy; an agent would have to read the entire document to find what it needs.
- 0–5: No description, no structure, wall of text.

**D5 — Tailoring to User Intent (0–20)**
- 16–20: Every section is customized to the user's stated purpose, chosen tech stack, and actual project structure — the skill reflects genuine understanding of the bootstrapped environment.
- 11–15: Partially adapted to the user intent but contains generic sections that could apply to any project.
- 6–10: Superficially references the user intent but the substance is generic.
- 0–5: Shows no adaptation to the specific user intent, installed packages, or library structure.

---

## Output Format

You MUST respond with ONLY the following JSON object, no other text:

{
  "score": <0-100 integer>,
  "dimensions": [
    { "dimension": "D1", "name": "Knowledge Delta", "score": <0-20>, "reasoning": "<1-2 sentences>" },
    { "dimension": "D2", "name": "Specificity & Actionability", "score": <0-20>, "reasoning": "<1-2 sentences>" },
    { "dimension": "D3", "name": "Anti-Patterns & Safety Boundaries", "score": <0-20>, "reasoning": "<1-2 sentences>" },
    { "dimension": "D4", "name": "Structure & Discoverability", "score": <0-20>, "reasoning": "<1-2 sentences>" },
    { "dimension": "D5", "name": "Tailoring to User Intent", "score": <0-20>, "reasoning": "<1-2 sentences>" }
  ]
}

The score MUST equal the sum of the five dimension scores. Each reasoning field must cite specific evidence from the generated output — never say "good" or "bad" without pointing to what you saw.`.trim();
